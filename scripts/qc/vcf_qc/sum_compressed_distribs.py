#!/usr/bin/env python
# -*- coding: utf-8 -*-
#
# The Germline Genomics of Cancer (G2C)
# Copyright (c) 2025-Present, Ryan L. Collins and the Dana-Farber Cancer Institute
# Contact: Ryan Collins <Ryan_Collins@dfci.harvard.edu>
# Distributed under the terms of the GNU GPL v2.0

"""
Sum compressed distributions generated by clean_site_metrics.py
"""


import argparse
import gzip
import numpy as np
from natsort import natsorted
from sys import stdout


def _sort_output(agg):
    """
    Sorts output aggregator according to desired variant class & subclass ordering
    """

    vc_sort_priority = {k : i for i, k in enumerate('snv indel sv'.split())}
    vsc_sort_priority = {k : i for i, k in enumerate('snv del ins DEL DUP CNV INS INV CPX CTX'.split())}

    def __parse_key(x):
        parts = x.split('\t')
        p1 = vc_sort_priority.get(parts[0], 10e10)
        p2 = vc_sort_priority.get(parts[1], 10e10)
        if len(parts) == 2:
            return p1, p2
        else:
            return p1, p2, *parts[2:]

    ordered_keys = natsorted(agg, key=lambda x: __parse_key(x))[::-1]

    return {k : agg[k] for k in ordered_keys}


def main():
    """
    Main block
    """
    parser = argparse.ArgumentParser(
             description=__doc__,
             formatter_class=argparse.RawDescriptionHelpFormatter)
    parser.add_argument('infile', nargs='+', metavar='.tsv',
                        help='One or more compressed distribution .tsvs ' +
                        'generated by clean_site_metrics.py')
    parser.add_argument('-k', '--key-columns', type=int, default=2, metavar='[int]',
                        help='Specify how many of the left-most columns should ' +
                        'be treated as keys for matching [default: 2]')
    parser.add_argument('-o', '--outfile', default='stdout', metavar='[tsv]',
                        help='Path to output file [default: stdout]')
    args = parser.parse_args()

    # Iterate over each input file
    agg = {}
    any_has_header = False
    for i, inpath in enumerate(args.infile):

        # Open connection
        if inpath.endswith('gz'):
            fin = gzip.open(inpath, mode='rt')
        else:
            fin = open(inpath)

        # Process each line
        for line in fin.readlines():
            lvals = line.rstrip().split('\t')

            # Check header. If first file, store as ref. If not, check vs. ref
            if line.startswith('#'):
                any_has_header = True
                if i == 0:
                    h_ref = line
                else:
                    if line != h_ref:
                        msg = 'Header in file {} did not match header of first file. Exiting.'
                        exit(msg.format(inpath))
                    else:
                        continue

            # Split line into keys & values depending on --key-columns
            else:
                key = '\t'.join(lvals[:args.key_columns])
                kvals = np.array([int(x) for x in lvals[args.key_columns:]])
                if key not in agg.keys():
                    agg[key] = kvals
                else:
                    agg[key] = agg[key] + kvals

    # Write aggregated results to --outfile
    if args.outfile in '- stdout /dev/stdout'.split():
        fout = stdout
    else:
        fout = open(args.outfile, 'w')
    if any_has_header:
        fout.write(h_ref)
    for k, v in _sort_output(agg).items():
        lout = k + '\t' + '\t'.join([str(x) for x in v])
        fout.write(lout + '\n')
    fout.close()


if __name__ == '__main__':
    main()
        
